import os
from typing import Optional

import streamlit as st
from openai import OpenAI

from moviepy.editor import (
    AudioFileClip,
    CompositeVideoClip,
    ColorClip,
    ImageClip,
)

import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageColor

# ====================================
# í˜ì´ì§€ ì„¤ì • (ì‚¬ì´ë“œë°” í•­ìƒ í¼ì³ë‘ê¸°!!)
# ====================================
st.set_page_config(
    page_title="SubKing",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded",
)

# =========================
# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# =========================
api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")

if not api_key:
    st.error(
        "OPENAI_API_KEY ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
        "- Streamlit Cloudì˜ 'Edit secrets'ì—ì„œ\n"
        '  OPENAI_API_KEY = "sk-..." í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•´ ì£¼ì„¸ìš”.'
    )
    st.stop()

client = OpenAI(api_key=api_key)

# í°íŠ¸ (ë ˆí¬ ë£¨íŠ¸ì— NanumGothic.ttf íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •)
FONT_PATH = os.path.join(os.path.dirname(__file__), "NanumGothic.ttf")


# ====================================
# 0) Pillowë¡œ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ë§Œë“œëŠ” í•¨ìˆ˜
# ====================================
def load_font(font_size: int) -> ImageFont.FreeTypeFont:
    """í•­ìƒ ë‚˜ëˆ”ê³ ë”•ì„ ìš°ì„  ì‚¬ìš© (ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸)."""
    if os.path.isfile(FONT_PATH):
        try:
            return ImageFont.truetype(FONT_PATH, font_size)
        except Exception:
            pass
    # í´ë°±
    try:
        return ImageFont.truetype("arial.ttf", font_size)
    except Exception:
        return ImageFont.load_default()


def hex_to_rgb(color_hex: str):
    """#RRGGBB í˜•íƒœë¥¼ (R,G,B) íŠœí”Œë¡œ ë³€í™˜."""
    try:
        return ImageColor.getrgb(color_hex)
    except Exception:
        return (255, 255, 255)


def make_text_image(
    text: str,
    width: int,
    font_size: int,
    text_color_hex: str,
    outline_color_hex: str,
    outline_width: int,
    line_spacing: int = 8,
    align: str = "center",  # "left", "center", "right"
):
    """
    Pillowë¥¼ ì´ìš©í•´ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±.
    í­(width)ì— ë§ê²Œ ìë™ ì¤„ë°”ê¿ˆ.
    align íŒŒë¼ë¯¸í„°ë¡œ ì¢Œ/ì¤‘ì•™/ìš° ì •ë ¬ ê°€ëŠ¥.
    """
    if not text:
        text = " "

    font = load_font(font_size)
    text_color = hex_to_rgb(text_color_hex)
    outline_color = hex_to_rgb(outline_color_hex)

    # ì¤„ë°”ê¿ˆ ê³„ì‚°ìš© ë”ë¯¸ ì´ë¯¸ì§€
    dummy_img = Image.new("RGBA", (width, font_size * 4), (0, 0, 0, 0))
    draw = ImageDraw.Draw(dummy_img)

    words = text.split(" ")
    lines = []
    current_line = ""
    for w in words:
        trial = (current_line + " " + w).strip()
        bbox = draw.textbbox((0, 0), trial, font=font)
        line_width = bbox[2] - bbox[0]
        if line_width <= width:
            current_line = trial
        else:
            if current_line:
                lines.append(current_line)
            current_line = w
    if current_line:
        lines.append(current_line)

    line_height = font_size + line_spacing
    img_height = line_height * len(lines)

    img = Image.new("RGBA", (width, img_height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)

    y = 0
    for line in lines:
        bbox = draw.textbbox((0, 0), line, font=font)
        line_width = bbox[2] - bbox[0]

        if align == "left":
            x = 0
        elif align == "right":
            x = width - line_width
        else:
            x = (width - line_width) // 2

        # ì™¸ê³½ì„ 
        if outline_width > 0:
            for dx in range(-outline_width, outline_width + 1):
                for dy in range(-outline_width, outline_width + 1):
                    if dx == 0 and dy == 0:
                        continue
                    draw.text((x + dx, y + dy), line, font=font, fill=outline_color)

        # ë³¸ í…ìŠ¤íŠ¸
        draw.text((x, y), line, font=font, fill=text_color)
        y += line_height

    return img


# ====================================
# 1) í…ìŠ¤íŠ¸ -> ìŒì„± (OpenAI TTS)
# ====================================
def generate_tts(
    text: str,
    voice: str = "alloy",
    output_path: str = "tts_audio.mp3",
) -> str:
    """
    í…ìŠ¤íŠ¸ë¥¼ OpenAI TTSë¡œ mp3 íŒŒì¼ë¡œ ì €ì¥.
    voice íŒŒë¼ë¯¸í„°ë¡œ ëª©ì†Œë¦¬ ì„ íƒ.
    """
    response = client.audio.speech.create(
        model="gpt-4o-mini-tts",
        voice=voice,
        input=text,
    )

    audio_bytes = response.read()

    with open(output_path, "wb") as f:
        f.write(audio_bytes)

    return output_path


# ====================================
# 2) ìŒì„± -> íƒ€ì„ìŠ¤íƒ¬í”„ (Whisper)
# ====================================
def extract_word_timestamps(audio_path: str):
    """
    Whisper(whisper-1)ë¡œ ë‹¨ì–´ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ.
    """
    with open(audio_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="verbose_json",
            timestamp_granularities=["word"],
        )

    words = getattr(transcript, "words", None)
    if words is None and isinstance(transcript, dict):
        words = transcript.get("words", [])

    if words is None:
        words = []

    return words


# ====================================
# 3-A) ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë” ê¸´ ìë§‰ ë©ì–´ë¦¬ë¡œ ê·¸ë£¹í•‘
# ====================================
def normalize_words(words):
    """Whisper ê²°ê³¼ë¥¼ dict ë¦¬ìŠ¤íŠ¸ë¡œ ì •ê·œí™”."""
    norm = []
    for w in words:
        if hasattr(w, "word"):
            norm.append({"word": w.word, "start": w.start, "end": w.end})
        else:
            norm.append(
                {"word": w["word"], "start": w["start"], "end": w["end"]}
            )
    return norm


def group_words_to_chunks(
    words,
    min_duration: float = 1.2,  # ìµœì†Œ ìë§‰ ìœ ì§€ ì‹œê°„(ì´ˆ)
    max_chars: int = 25,        # í•œ ìë§‰ ë¸”ë¡ì˜ ìµœëŒ€ ê¸€ì ìˆ˜
):
    """
    ë„ˆë¬´ ìì£¼ ë°”ë€Œì§€ ì•Šë„ë¡ ë‹¨ì–´ë“¤ì„ ë¬¶ì–´ì„œ í•œ ë¸”ë¡ìœ¼ë¡œ ë§Œë“œëŠ” í•¨ìˆ˜.
    """
    words = normalize_words(words)
    chunks = []
    current_text = ""
    current_start: Optional[float] = None
    current_end: Optional[float] = None

    for w in words:
        word = w["word"]
        start = w["start"]
        end = w["end"]

        if current_text == "":
            current_text = word
            current_start = start
            current_end = end
        else:
            trial = current_text + " " + word
            trial_len = len(trial)
            duration = end - (current_start if current_start is not None else start)

            if duration >= min_duration or trial_len > max_chars:
                chunks.append(
                    {
                        "text": current_text,
                        "start": current_start,
                        "end": current_end,
                    }
                )
                current_text = word
                current_start = start
                current_end = end
            else:
                current_text = trial
                current_end = end

    if current_text and current_start is not None and current_end is not None:
        chunks.append(
            {"text": current_text, "start": current_start, "end": current_end}
        )

    return chunks


# ====================================
# 3-B) íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ìë§‰ + ë°°ê²½ í´ë¦½ ìƒì„±
# ====================================
def build_video_clips_from_chunks(
    chunks,
    video_size=(1080, 1920),
    font_size: int = 70,
    text_color_hex: str = "#FFFFFF",
    outline_color_hex: str = "#000000",
    outline_width: int = 3,
    y_ratio: float = 0.8,  # 0.0(ë§¨ ìœ„) ~ 1.0(ë§¨ ì•„ë˜)
    line_spacing: int = 8,
):
    """
    ìë§‰ ë¸”ë¡(chunks) ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ìë§‰ ì´ë¯¸ì§€ í´ë¦½ + ë°°ê²½ í´ë¦½ ìƒì„±.
    """
    W, H = video_size
    clips = []

    if not chunks:
        return clips, 0.0

    last_end = max(c["end"] for c in chunks)

    bg = ColorClip(size=(W, H), color=(0, 0, 0), duration=last_end)
    clips.append(bg)

    y_pos = int(H * y_ratio)

    for c in chunks:
        txt = c["text"]
        start = c["start"]
        end = c["end"]
        if end <= start:
            continue
        duration = end - start

        img = make_text_image(
            txt,
            width=W - 200,
            font_size=font_size,
            text_color_hex=text_color_hex,
            outline_color_hex=outline_color_hex,
            outline_width=outline_width,
            line_spacing=line_spacing,
            align="center",
        )

        img_array = np.array(img)
        text_clip = (
            ImageClip(img_array)
            .set_duration(duration)
            .set_start(start)
            .set_position(("center", y_pos))
        )

        clips.append(text_clip)

    return clips, last_end


# ====================================
# 3-C) ì œëª©(4ì¤„) í´ë¦½ ìƒì„±
# ====================================
def build_title_clips(
    title_lines,
    video_size,
    duration,
    font_size: int,
    outline_width: int,
    line_spacing: int,
    text_colors,
    outline_colors,
    aligns,
    top_ratio: float,
):
    """
    ì œëª© 4ì¤„ì„ í™”ë©´ ìƒë‹¨ë¶€í„° ì„¸ë¡œë¡œ ë°°ì¹˜í•˜ëŠ” í´ë¦½ ìƒì„±.
    ê° ì¤„ì€ ìƒ‰ìƒ/ì™¸ê³½ì„ ìƒ‰/ì •ë ¬ì„ ê°œë³„ ì„¤ì •.
    """
    W, H = video_size
    clips = []
    safe_width = W - 200  # ì¢Œìš° ì—¬ë°± í™•ë³´

    y = int(H * top_ratio)

    for idx, line in enumerate(title_lines):
        if not line or not line.strip():
            continue

        text_color = text_colors[idx] if text_colors and idx < len(text_colors) else "#FFFFFF"
        outline_color = outline_colors[idx] if outline_colors and idx < len(outline_colors) else "#000000"
        align = aligns[idx] if aligns and idx < len(aligns) else "center"

        img = make_text_image(
            line,
            width=safe_width,
            font_size=font_size,
            text_color_hex=text_color,
            outline_color_hex=outline_color,
            outline_width=outline_width,
            line_spacing=line_spacing,
            align=align,
        )

        img_array = np.array(img)
        clip = (
            ImageClip(img_array)
            .set_duration(duration)
            .set_start(0)  # ì „ì²´ êµ¬ê°„ ë™ì•ˆ ë…¸ì¶œ
            .set_position(("center", y))
        )
        clips.append(clip)

        y += font_size + line_spacing

    return clips


# ====================================
# 4) ìŒì„± + ìë§‰(+ì œëª©) -> mp4 ì˜ìƒ ë§Œë“¤ê¸°
# ====================================
def create_video_with_subtitles(
    audio_path: str,
    words,
    video_size=(1080, 1920),
    font_size: int = 70,
    text_color_hex: str = "#FFFFFF",
    outline_color_hex: str = "#000000",
    outline_width: int = 3,
    y_ratio: float = 0.8,
    output_path: str = "subking_result.mp4",
    # --- ì œëª© ê´€ë ¨ ì˜µì…˜ ---
    title_lines=None,
    title_aligns=None,
    title_text_colors=None,
    title_outline_colors=None,
    title_font_size: int = 80,
    title_outline_width: int = 4,
    title_line_spacing: int = 10,
    title_top_ratio: float = 0.1,
):
    if title_lines is None:
        title_lines = []
    if title_aligns is None:
        title_aligns = []
    if title_text_colors is None:
        title_text_colors = []
    if title_outline_colors is None:
        title_outline_colors = []

    chunks = group_words_to_chunks(words)
    clips, duration = build_video_clips_from_chunks(
        chunks,
        video_size=video_size,
        font_size=font_size,
        text_color_hex=text_color_hex,
        outline_color_hex=outline_color_hex,
        outline_width=outline_width,
        y_ratio=y_ratio,
        line_spacing=8,
    )
    if duration <= 0:
        return None

    # ì œëª© í´ë¦½ ì¶”ê°€
    if any(line.strip() for line in title_lines):
        title_clips = build_title_clips(
            title_lines=title_lines,
            video_size=video_size,
            duration=duration,
            font_size=title_font_size,
            outline_width=title_outline_width,
            line_spacing=title_line_spacing,
            text_colors=title_text_colors,
            outline_colors=title_outline_colors,
            aligns=title_aligns,
            top_ratio=title_top_ratio,
        )
        clips.extend(title_clips)

    video = CompositeVideoClip(clips)
    audio = AudioFileClip(audio_path)
    video = video.set_audio(audio)

    video.write_videofile(
        output_path,
        fps=30,
        codec="libx264",
        audio_codec="aac",
        verbose=False,
        logger=None,
    )

    return output_path


# ====================================
# 5) ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ìƒì„± (Streamlit UIìš©)
# ====================================
def create_preview_frame(
    video_size=(1080, 1920),
    font_size: int = 70,
    text_color_hex: str = "#FFFFFF",
    outline_color_hex: str = "#000000",
    outline_width: int = 3,
    y_ratio: float = 0.8,
    sample_text: str = "ì—¬ê¸°ì„œëŠ” ìë§‰ì´ ì˜¬ë¼ê°‘ë‹ˆë‹¤",
):
    W, H = video_size

    bg = Image.new("RGB", (W, H), (0, 0, 0))

    subtitle_img = make_text_image(
        sample_text,
        width=W - 200,
        font_size=font_size,
        text_color_hex=text_color_hex,
        outline_color_hex=outline_color_hex,
        outline_width=outline_width,
        line_spacing=8,
        align="center",
    )

    sw, sh = subtitle_img.size
    y_pos = int(H * y_ratio) - sh // 2
    x_pos = (W - sw) // 2

    bg.paste(subtitle_img, (x_pos, y_pos), subtitle_img)

    preview = bg.resize((W // 2, H // 2), Image.LANCZOS)
    return preview


# ====================================
# 6) Streamlit UI
# ====================================

# ---------- ì™¼ìª½ ì‚¬ì´ë“œë°” ----------
side = st.sidebar
side.title("âš™ï¸ SubKing ì„¤ì •")

# ì˜ìƒ ë¹„ìœ¨ ì„ íƒ
ratio_label = side.radio(
    "ì˜ìƒ ë¹„ìœ¨ ì„ íƒ",
    ("9:16 ì‡¼ì¸  (1080x1920)", "16:9 ë¡¤í¼ (1920x1080)"),
)

if "9:16" in ratio_label:
    video_size = (1080, 1920)
else:
    video_size = (1920, 1080)

side.markdown("---")

# TTS ëª©ì†Œë¦¬ ì„ íƒ
voice_options = [
    "alloy",
    "ash",
    "ballad",
    "coral",
    "echo",
    "fable",
    "onyx",
    "nova",
    "sage",
    "shimmer",
    "verse",
]
selected_voice = side.selectbox("ğŸ™ TTS ëª©ì†Œë¦¬ ì„ íƒ", options=voice_options, index=0)

side.markdown("---")

# ìë§‰ ìŠ¤íƒ€ì¼ (Disclosure / Expander)
with side.expander("ğŸ¨ ìë§‰ ìŠ¤íƒ€ì¼", expanded=True):
    font_size = st.slider(
        "ìë§‰ í°íŠ¸ í¬ê¸°", min_value=40, max_value=120, value=80, step=2
    )
    text_color = st.color_picker("ìë§‰ ê¸€ì ìƒ‰ìƒ", "#FFFFFF")

    outline_width = st.slider(
        "í…ìŠ¤íŠ¸ ì™¸ê³½ì„  ë‘ê»˜", min_value=0, max_value=8, value=4
    )
    outline_color = st.color_picker("ì™¸ê³½ì„  ìƒ‰ìƒ", "#000000")

    pos_percent = st.slider(
        "ìë§‰ ì„¸ë¡œ ìœ„ì¹˜ (0 = ë§¨ ìœ„, 100 = ë§¨ ì•„ë˜)",
        min_value=50,
        max_value=95,
        value=80,
    )
    y_ratio = pos_percent / 100.0

    st.markdown("---")
    st.subheader("ğŸ‘€ ìë§‰ ë¯¸ë¦¬ë³´ê¸°")
    preview_img = create_preview_frame(
        video_size=video_size,
        font_size=font_size,
        text_color_hex=text_color,
        outline_color_hex=outline_color,
        outline_width=outline_width,
        y_ratio=y_ratio,
        sample_text="ì—¬ê¸°ì„œëŠ” ìë§‰ì´ ì˜¬ë¼ê°‘ë‹ˆë‹¤",
    )
    st.image(preview_img, use_container_width=True, caption="í˜„ì¬ ìë§‰ ì„¤ì • ë¯¸ë¦¬ë³´ê¸°")

# ì œëª© ìŠ¤íƒ€ì¼ (Disclosure / Expander)
with side.expander("ğŸ“ ì œëª© ìŠ¤íƒ€ì¼", expanded=False):
    st.markdown("ì œëª©ì€ ìµœëŒ€ 4ì¤„ê¹Œì§€ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    title_font_size = st.slider(
        "ì œëª© í°íŠ¸ í¬ê¸°", min_value=40, max_value=150, value=90, step=2
    )
    title_outline_width = st.slider(
        "ì œëª© ì™¸ê³½ì„  ë‘ê»˜", min_value=0, max_value=10, value=4
    )
    title_line_spacing = st.slider(
        "ì œëª© ì¤„ ê°„ê²©(í”½ì…€)", min_value=0, max_value=80, value=10
    )
    title_pos_percent = st.slider(
        "ì œëª© ë¸”ë¡ ìƒë‹¨ ìœ„ì¹˜ (0 = ë§¨ ìœ„, 100 = ë§¨ ì•„ë˜)",
        min_value=0,
        max_value=40,
        value=10,
    )
    title_top_ratio = title_pos_percent / 100.0

    st.markdown("---")
    st.markdown("**ì œëª© í…ìŠ¤íŠ¸ & ê° ì¤„ ìŠ¤íƒ€ì¼**")

    title_lines = []
    title_aligns = []
    title_text_colors = []
    title_outline_colors = []

    align_label_to_value = {"ì¢Œì¸¡": "left", "ê°€ìš´ë°": "center", "ìš°ì¸¡": "right"}

    for i in range(4):
        st.markdown(f"**ì œëª© {i+1} ì¤„**")
        line = st.text_input(
            f"ì œëª© {i+1} ì¤„ ë‚´ìš©", key=f"title_line_{i+1}", placeholder="ë¹„ì›Œë‘ë©´ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )
        align_label = st.selectbox(
            f"ì •ë ¬ (ì œëª© {i+1} ì¤„)",
            options=["ì¢Œì¸¡", "ê°€ìš´ë°", "ìš°ì¸¡"],
            index=1,
            key=f"title_align_{i+1}",
        )
        text_color_line = st.color_picker(
            f"ê¸€ì ìƒ‰ìƒ (ì œëª© {i+1} ì¤„)", "#FFFFFF", key=f"title_color_{i+1}"
        )
        outline_color_line = st.color_picker(
            f"ì™¸ê³½ì„  ìƒ‰ìƒ (ì œëª© {i+1} ì¤„)", "#000000", key=f"title_outline_color_{i+1}"
        )

        title_lines.append(line)
        title_aligns.append(align_label_to_value[align_label])
        title_text_colors.append(text_color_line)
        title_outline_colors.append(outline_color_line)

        st.markdown("---")

# ---------- ë©”ì¸ ì˜ì—­ ----------
st.title("ğŸ¬ SubKing - í…ìŠ¤íŠ¸ë¡œ ìŒì„± + ìë§‰ ì˜ìƒ ë§Œë“¤ê¸°")

script = st.text_area(
    "ğŸ§ ìŒì„±ìœ¼ë¡œ ì½ì–´ ì¤„ ëŒ€ë³¸ì„ ì…ë ¥í•˜ì„¸ìš”",
    height=300,
    placeholder="ì—¬ê¸°ì— ì½ì–´ ì¤„ ë¬¸ì¥ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
)

if st.button("ğŸ¤ ìŒì„± + ìë§‰ ì˜ìƒ ìƒì„±"):
    if not script.strip():
        st.error("ëŒ€ë³¸ì„ ë¨¼ì € ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        st.stop()

    with st.status("TTS ìƒì„± ì¤‘...", expanded=True) as status:
        audio_path = generate_tts(script, voice=selected_voice)
        status.update(label="íƒ€ì„ìŠ¤íƒ¬í”„ ë¶„ì„ ì¤‘ (Whisper)...", state="running")

        words = extract_word_timestamps(audio_path)
        if not words:
            status.update(
                label="íƒ€ì„ìŠ¤íƒ¬í”„ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.",
                state="error",
            )
            st.stop()

        status.update(label="ì˜ìƒ ë Œë”ë§ ì¤‘ (MoviePy)...", state="running")

        video_path = create_video_with_subtitles(
            audio_path=audio_path,
            words=words,
            video_size=video_size,
            font_size=font_size,
            text_color_hex=text_color,
            outline_color_hex=outline_color,
            outline_width=outline_width,
            y_ratio=y_ratio,
            output_path="subking_result.mp4",
            # ì œëª© ì˜µì…˜ ì „ë‹¬
            title_lines=title_lines,
            title_aligns=title_aligns,
            title_text_colors=title_text_colors,
            title_outline_colors=title_outline_colors,
            title_font_size=title_font_size,
            title_outline_width=title_outline_width,
            title_line_spacing=title_line_spacing,
            title_top_ratio=title_top_ratio,
        )

        if not video_path:
            status.update(label="ì˜ìƒ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", state="error")
            st.stop()

        status.update(label="ì™„ë£Œ! ğŸ‰", state="complete")

    st.success("ì˜ìƒì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.video(video_path)

    with open(video_path, "rb") as f:
        st.download_button(
            "ğŸ“¥ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
            f,
            file_name="subking_result.mp4",
            mime="video/mp4",
        )
