import os
import re
import tempfile
from pathlib import Path

import streamlit as st
from moviepy.editor import AudioFileClip, VideoClip
import numpy as np
from PIL import Image, ImageDraw, ImageFont

from elevenlabs.client import ElevenLabs
from elevenlabs import VoiceSettings


# =========================
# 1. ElevenLabs ì„¤ì •
# =========================
ELEVEN_KEY = (
    os.getenv("ELEVENLABS_API_KEY")
    or st.secrets.get("ELEVENLABS_API_KEY", None)
)

if not ELEVEN_KEY:
    st.error("âŒ ELEVENLABS_API_KEY ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

eleven = ElevenLabs(api_key=ELEVEN_KEY)

VOICE_PRESETS = {
    "Adam (ë‚¨)": "pNInz6obpgDQGcFmaJgB",
    "Rachel (ì—¬)": "21m00Tcm4TlvDq8ikWAM",
    "Callum (ë‚¨)": "N2lVS1w4EtoT3dr4eOWO",
    "Elli (ì—¬)": "MF3mGyEYCl7XYWbV9V6O",
}


# =========================
# 2. ëŒ€ë³¸ â†’ ë¬¸ì¥(ìë§‰) ë¦¬ìŠ¤íŠ¸
# =========================
def split_script(text: str, max_chars: int = 28) -> list[str]:
    parts = re.split(r'(?<=[\.\!\?ã€‚ï¼Ÿï¼])\s+|\n+', text.strip())
    result = []

    for p in parts:
        p = p.strip()
        if not p:
            continue

        while len(p) > max_chars:
            result.append(p[:max_chars])
            p = p[max_chars:]

        result.append(p)

    return result


def build_subtitles(
    text: str,
    cps: float = 8.0,
    min_dur: float = 1.5,
    gap: float = 0.2,
    max_chars: int = 28,
):
    seg = split_script(text, max_chars=max_chars)
    subs = []
    now = 0.0

    for idx, s in enumerate(seg, 1):
        dur = max(min_dur, len(s) / cps)
        subs.append({
            "index": idx,
            "text": s,
            "start": now,
            "end": now + dur,
        })
        now += dur + gap

    return subs


# =========================
# 3. ElevenLabs ìŒì„± ìƒì„±
# =========================
def tts_elevenlabs(
    text: str,
    voice_id: str,
    stability: float,
    similarity: float,
):
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tmp.close()
    out_path = Path(tmp.name)

    res = eleven.text_to_speech.convert(
        text=text,
        voice_id=voice_id,
        model_id="eleven_multilingual_v2",
        output_format="mp3_44100_128",
        voice_settings=VoiceSettings(
            stability=stability,
            similarity_boost=similarity,
            style=0.0,
            use_speaker_boost=True,
        ),
    )

    # chunk-by-chunk streaming write
    with open(out_path, "wb") as f:
        for chunk in res:
            if chunk:
                f.write(chunk)

    return str(out_path)


# =========================
# 4. ìë§‰ ë Œë”ë§(PIL)
# =========================
def load_font(size: int):
    try:
        return ImageFont.truetype("DejaVuSans.ttf", size)
    except:
        return ImageFont.load_default()


def wrap_text(draw, text, font, max_width):
    chars = list(text)
    lines = []
    cur = chars[0] if chars else ""

    for ch in chars[1:]:
        test = cur + ch
        box = draw.textbbox((0, 0), test, font=font)
        if box[2] <= max_width:
            cur = test
        else:
            lines.append(cur)
            cur = ch
    lines.append(cur)
    return "\n".join(lines)


def render_frame(
    text: str,
    w: int,
    h: int,
    fontsize: int,
    bottom: int,
    color: str,
    bg,
    ratio: float,
):
    img = Image.new("RGB", (w, h), bg)
    if not text.strip():
        return img

    draw = ImageDraw.Draw(img)
    font = load_font(fontsize)
    max_w = int(w * ratio)
    wrapped = wrap_text(draw, text, font, max_w)

    box = draw.multiline_textbbox((0, 0), wrapped, font=font)
    tw, th = box[2], box[3]

    x = (w - tw) // 2
    y = h - bottom - th

    draw.multiline_text((x, y), wrapped, font=font, fill=color, align="center")
    return img


# =========================
# 5. ìë§‰ + ì˜¤ë””ì˜¤ â†’ ì˜ìƒ ìƒì„±
# =========================
def build_video(
    audio_path: str,
    subtitles: list,
    w: int,
    h: int,
    fontsize: int,
    bottom: int,
    color: str,
    bg,
    ratio: float,
    fps: int = 30,
):
    audio = AudioFileClip(audio_path)
    duration = audio.duration

    def frame(t):
        text = ""
        for s in subtitles:
            if s["start"] <= t < s["end"]:
                text = s["text"]
                break
        img = render_frame(text, w, h, fontsize, bottom, color, bg, ratio)
        return np.array(img)

    clip = VideoClip(frame, duration=duration).set_audio(audio)

    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tmp.close()
    out = tmp.name

    clip.write_videofile(
        out,
        fps=fps,
        codec="libx264",
        audio_codec="aac",
        verbose=False,
        logger=None,
    )
    clip.close()
    audio.close()
    return out


# =========================
# 6. Streamlit UI (ë¯¸ë¦¬ë³´ê¸° ì—†ìŒ)
# =========================
st.set_page_config(page_title="SubKing - ElevenLabs ìë§‰ì˜ìƒ", layout="centered")

st.title("ğŸ¬ SubKing â€“ ElevenLabs ê¸°ë°˜ ëŒ€ë³¸ â†’ ìŒì„±Â·ìë§‰ ì˜ìƒ ìƒì„±ê¸°")

script = st.text_area(
    "ëŒ€ë³¸ ì…ë ¥",
    height=280,
    placeholder="ëŒ€ë³¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
)


with st.expander("â± ìë§‰ ì†ë„/ê¸¸ì´ ì¡°ì ˆ"):
    max_chars = st.slider("ìë§‰ ìµœëŒ€ ê¸€ììˆ˜", 12, 40, 28, 2)
    cps = st.slider("ì´ˆë‹¹ ê¸€ì ìˆ˜", 3.0, 20.0, 8.0, 0.5)
    min_dur = st.slider("ìµœì†Œ í‘œì‹œ ì‹œê°„(ì´ˆ)", 0.5, 5.0, 1.5, 0.1)
    gap = st.slider("ë¬¸ì¥ ì‚¬ì´ ì‰¬ëŠ” ì‹œê°„(ì´ˆ)", 0.0, 2.0, 0.2, 0.1)

with st.expander("ğŸ¨ ìë§‰ ìŠ¤íƒ€ì¼"):
    fontsize = st.slider("ê¸€ì í¬ê¸°", 30, 90, 60, 2)
    bottom = st.slider("ì•„ë˜ ì—¬ë°±(px)", 100, 500, 280, 10)
    ratio = st.slider("ìë§‰ ê°€ë¡œí­ ë¹„ìœ¨", 0.5, 0.95, 0.8, 0.05)
    color = st.selectbox("ê¸€ììƒ‰", ["white", "yellow"])
    bg_choice = st.selectbox("ë°°ê²½ìƒ‰", ["black", "dark_gray", "navy"])
    bg = (0, 0, 0) if bg_choice == "black" else (20, 20, 20) if bg_choice == "dark_gray" else (10, 10, 40)

with st.expander("ğŸ™ ElevenLabs ëª©ì†Œë¦¬"):
    preset = st.selectbox("í”„ë¦¬ì…‹", list(VOICE_PRESETS.keys()), index=0)
    custom_id = st.text_input("voice_id ì§ì ‘ ì…ë ¥ (ì„ íƒ)")
    stability = st.slider("Stability", 0.0, 1.0, 0.6, 0.05)
    similarity = st.slider("Similarity Boost", 0.0, 1.0, 0.8, 0.05)

generate = st.button("ğŸ“½ ì˜ìƒ ìƒì„±í•˜ê¸°", use_container_width=True)

W, H = 1080, 1920

if generate:
    if not script.strip():
        st.warning("ëŒ€ë³¸ì„ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    voice_id = custom_id.strip() or VOICE_PRESETS[preset]

    with st.spinner("1/3 ìë§‰ ìƒì„± ì¤‘..."):
        subs = build_subtitles(script, cps, min_dur, gap, max_chars)

    with st.spinner("2/3 ElevenLabs ìŒì„± ìƒì„± ì¤‘..."):
        audio_path = tts_elevenlabs(script, voice_id, stability, similarity)

    with st.spinner("3/3 ì˜ìƒ ë Œë”ë§ ì¤‘..."):
        video_path = build_video(
            audio_path,
            subs,
            W,
            H,
            fontsize,
            bottom,
            color,
            bg,
            ratio,
        )

    st.success("ì™„ë£Œ!")
    with open(video_path, "rb") as f:
        st.video(f.read())

    st.download_button(
        "ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
        data=open(video_path, "rb").read(),
        file_name="subking_elevenlabs.mp4",
        mime="video/mp4",
    )
