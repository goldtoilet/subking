import os
import re
import tempfile
from pathlib import Path

import streamlit as st
from openai import OpenAI
from moviepy.editor import AudioFileClip, VideoClip
import numpy as np
from PIL import Image, ImageDraw, ImageFont

# =========================
# OpenAI ì„¤ì •
# =========================
API_KEY = os.getenv("GPT_API_KEY") or st.secrets.get("GPT_API_KEY", None)

if not API_KEY:
    st.error("GPT_API_KEY í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” .streamlit/secrets.toml ì— GPT_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=API_KEY)


# =========================
# 1. ëŒ€ë³¸ â†’ ìë§‰ìš© ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
# =========================
def split_script_to_segments(text: str, max_chars_per_sub: int = 28) -> list[str]:
    """
    'ë³´í†µ ì‚¬ëŒì´ ì“°ëŠ” ëŒ€ë³¸' ê¸°ì¤€:
      - ì¤„ë°”ê¿ˆ, ë§ˆì¹¨í‘œ(., ?, !, ã€‚, ï¼Ÿ, ï¼)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•œ ë²ˆ ë¬¸ì¥ì„ ë‚˜ëˆ„ê³ 
      - ê° ë¬¸ì¥ì´ ë„ˆë¬´ ê¸¸ë©´ max_chars_per_sub ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ì—¬ëŸ¬ ìë§‰ìœ¼ë¡œ ë§Œë“ ë‹¤.
    ê²°ê³¼ì ìœ¼ë¡œ í•œ ë²ˆì— í•œ ë¬¸ì¥(í˜¹ì€ ì§§ì€ êµ¬ì ˆ)ë§Œ ìë§‰ì— ëœ¨ë„ë¡.
    """
    # ì¤„ë°”ê¿ˆ + ë¬¸ì¥ë¶€í˜¸ ê¸°ì¤€ìœ¼ë¡œ 1ì°¨ ë¶„ë¦¬
    raw_chunks = re.split(r'(?<=[\.!?ã€‚ï¼Ÿï¼])\s+|\n+', text.strip())
    segments = []

    for chunk in raw_chunks:
        chunk = chunk.strip()
        if not chunk:
            continue

        # ë„ˆë¬´ ê¸´ ë¬¸ì¥ì€ max_chars_per_sub ê¸¸ì´ë¡œ ë‹¤ì‹œ ìª¼ê° ë‹¤ (í•œêµ­ì–´ë¼ ê³µë°± ê¸°ì¤€ ë§ê³  ë¬¸ì ê¸¸ì´ ê¸°ì¤€)
        while len(chunk) > max_chars_per_sub:
            segments.append(chunk[:max_chars_per_sub])
            chunk = chunk[max_chars_per_sub:]
        if chunk:
            segments.append(chunk)

    return segments


def build_subtitles(
    text: str,
    chars_per_second: float = 8.0,
    min_duration: float = 1.5,
    gap_between_lines: float = 0.2,
    max_chars_per_sub: int = 28,
) -> list[dict]:
    """
    ëŒ€ë³¸ ì „ì²´ â†’ ìë§‰ ë¦¬ìŠ¤íŠ¸
      - split_script_to_segments ë¡œ ì˜ê²Œ ìª¼ê°  ë¬¸ì¥ë“¤ì„ ìˆœì„œëŒ€ë¡œ ë°°ì¹˜
      - ê° ë¬¸ì¥ì˜ ê¸¸ì´ì— ë”°ë¼ ìë™ìœ¼ë¡œ duration ê³„ì‚°
    """
    segments = split_script_to_segments(text, max_chars_per_sub=max_chars_per_sub)
    subtitles = []
    current_time = 0.0

    for idx, seg in enumerate(segments, start=1):
        seg_len = max(len(seg), 1)
        dur = max(min_duration, seg_len / chars_per_second)
        start = current_time
        end = start + dur
        subtitles.append(
            {"index": idx, "start": start, "end": end, "text": seg}
        )
        current_time = end + gap_between_lines

    return subtitles


# =========================
# 2. TTS (í…ìŠ¤íŠ¸ â†’ ìŒì„±)
# =========================
def generate_tts_audio(text: str, voice: str = "alloy", speed: float = 1.0) -> str:
    """
    ChatGPT TTS (gpt-4o-mini-tts)ë¡œ mp3 ìƒì„±
    voice: alloy, ash, ballad, coral, echo, fable, onyx, nova, sage, shimmer, verse
    speed: 0.25 ~ 4.0
    """
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tmp.close()
    out_path = Path(tmp.name)

    with client.audio.speech.with_streaming_response.create(
        model="gpt-4o-mini-tts",
        voice=voice,
        input=text,
        speed=speed,
    ) as response:
        response.stream_to_file(out_path)

    return str(out_path)


# =========================
# 3. PIL ê¸°ë°˜ ìë§‰ ë Œë”ë§
# =========================
def _load_font(font_size: int) -> ImageFont.FreeTypeFont:
    try:
        return ImageFont.truetype("DejaVuSans.ttf", font_size)
    except Exception:
        return ImageFont.load_default()


def _wrap_text_to_width(draw, text, font, max_width: int) -> str:
    """
    ê°€ë¡œí­ ì•ˆì— ë“¤ì–´ê°€ë„ë¡ ì—¬ëŸ¬ ì¤„ë¡œ ê°œí–‰.
    (í•œêµ­ì–´ë„ ê·¸ëƒ¥ ë¬¸ì ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ë„£ëŠ” ë°©ì‹ì´ë¼ ì¶©ë¶„íˆ ë¬´ë‚œí•˜ê²Œ ë³´ì¸ë‹¤)
    """
    words = list(text)  # ë¬¸ì ë‹¨ìœ„ë¡œ
    if not words:
        return ""

    lines = []
    current = words[0]
    for ch in words[1:]:
        test = current + ch
        bbox = draw.textbbox((0, 0), test, font=font)
        if bbox[2] - bbox[0] <= max_width:
            current = test
        else:
            lines.append(current)
            current = ch
    lines.append(current)
    return "\n".join(lines)


def draw_subtitle_frame(
    text: str,
    video_width: int,
    video_height: int,
    subtitle_fontsize: int,
    subtitle_bottom_margin: int,
    text_color: str,
    bg_color,
    max_text_width_ratio: float,
) -> Image.Image:
    img = Image.new("RGB", (video_width, video_height), bg_color)
    if not text.strip():
        return img

    draw = ImageDraw.Draw(img)
    font = _load_font(subtitle_fontsize)

    max_text_width = int(video_width * max_text_width_ratio)
    wrapped = _wrap_text_to_width(draw, text, font, max_text_width)

    bbox = draw.multiline_textbbox((0, 0), wrapped, font=font, align="center")
    text_w = bbox[2] - bbox[0]
    text_h = bbox[3] - bbox[1]

    x = (video_width - text_w) // 2
    y = video_height - subtitle_bottom_margin - text_h

    draw.multiline_text((x, y), wrapped, font=font, fill=text_color, align="center")
    return img


# =========================
# 4. ìë§‰ + ìŒì„± â†’ ì˜ìƒ
# =========================
def subtitles_to_video(
    audio_path: str,
    subtitles: list[dict],
    video_width: int,
    video_height: int,
    subtitle_fontsize: int,
    subtitle_bottom_margin: int,
    text_color: str,
    bg_color,
    max_text_width_ratio: float,
    fps: int = 30,
) -> str:
    audio = AudioFileClip(audio_path)
    duration = audio.duration

    def make_frame(t):
        current_text = ""
        for sub in subtitles:
            if sub["start"] <= t < sub["end"]:
                current_text = sub["text"]
                break
        frame_img = draw_subtitle_frame(
            current_text,
            video_width,
            video_height,
            subtitle_fontsize,
            subtitle_bottom_margin,
            text_color,
            bg_color,
            max_text_width_ratio,
        )
        return np.array(frame_img)

    video_clip = VideoClip(make_frame, duration=duration).set_audio(audio)

    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tmp.close()
    out_path = tmp.name

    video_clip.write_videofile(
        out_path,
        fps=fps,
        codec="libx264",
        audio_codec="aac",
        verbose=False,
        logger=None,
    )

    video_clip.close()
    audio.close()
    return out_path


def generate_preview_image(
    subtitles: list[dict],
    video_width: int,
    video_height: int,
    subtitle_fontsize: int,
    subtitle_bottom_margin: int,
    text_color: str,
    bg_color,
    max_text_width_ratio: float,
) -> Image.Image:
    """
    ì²« ë²ˆì§¸ ìë§‰ ë¬¸ì¥ì„ ì´ìš©í•´ì„œ í™”ë©´ì— ì–´ë–»ê²Œ ë³´ì¼ì§€ ë¯¸ë¦¬ë³´ê¸°.
    """
    first_text = subtitles[0]["text"] if subtitles else "ë¯¸ë¦¬ë³´ê¸°"
    return draw_subtitle_frame(
        first_text,
        video_width,
        video_height,
        subtitle_fontsize,
        subtitle_bottom_margin,
        text_color,
        bg_color,
        max_text_width_ratio,
    )


# =========================
# 5. Streamlit UI
# =========================
st.set_page_config(page_title="SubKing - ëŒ€ë³¸ â†’ ìŒì„±+ìë§‰ ì˜ìƒ", layout="centered")

st.title("ğŸ¬ SubKing â€“ ëŒ€ë³¸ìœ¼ë¡œ ìŒì„±+ìë§‰ ì˜ìƒ ë§Œë“¤ê¸°")

st.markdown(
    """
**1ë‹¨ê³„. ëŒ€ë³¸ ì…ë ¥**  
- í‰ì†Œ ì“°ëŠ” ëŒ€ë³¸ì²˜ëŸ¼ **ê·¸ëƒ¥ ë¬¸ì¥ ë‹¨ìœ„ë¡œ** ì­‰ ì¨ì£¼ì„¸ìš”.  
- ì¤„ë°”ê¿ˆì„ í•´ë„ ë˜ê³ , ë§ˆì¹¨í‘œ(., ?, !) ê¸°ì¤€ìœ¼ë¡œë„ ìë™ìœ¼ë¡œ ì˜ë¼ì„œ ìë§‰ì„ ë§Œë“¤ì–´ìš”.

**2ë‹¨ê³„. ìë§‰/í™”ë©´ ìŠ¤íƒ€ì¼ê³¼ ëª©ì†Œë¦¬ ì„ íƒ**  
- ìë§‰ ì†ë„, í•œ ë¬¸ì¥ ìµœì†Œ ì‹œê°„, ìë§‰ ìœ„ì¹˜, ê¸€ì í¬ê¸° ì¡°ì ˆ  
- ëª©ì†Œë¦¬(voice)ì™€ ìŒì„± ì†ë„(speed) ì„ íƒ

**3ë‹¨ê³„. ìë§‰ ë¯¸ë¦¬ë³´ê¸° â†’ ì˜ìƒ ìƒì„±**
"""
)

# ---- ëŒ€ë³¸ ì…ë ¥ ----
script_text = st.text_area(
    "ëŒ€ë³¸ ì…ë ¥",
    height=260,
    placeholder="ì˜ˆ)\nì¸ë¥˜ì˜ ê¸°ìˆ  ë°œì „ì€ ëŠì„ì—†ëŠ” íƒìƒ‰ê³¼ ë„ì „ì˜ ì—°ì†ì´ì—ˆë‹¤. ê·¸ ì¤‘ì—ì„œë„ ììœ¨ì£¼í–‰ì°¨ë¼ëŠ” í˜ì‹ ì€ ë‹¤ì–‘í•œ ê°€ëŠ¥ì„±ì„ ì œì‹œí•˜ë©° í˜„ëŒ€ ì‚¬íšŒë¥¼ ë³€í™”ì‹œí‚¤ê³  ìˆë‹¤.\níŠ¹íˆ FSD ê¸°ìˆ ì€ ì¸ê°„ì˜ ê°œì… ì—†ì´ ì°¨ëŸ‰ì´ ì£¼ë³€ í™˜ê²½ì„ ì¸ì‹í•˜ê³  ì£¼í–‰ì„ ê²°ì •í•˜ëŠ” ê²½í—˜ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.\n...",
)

# ---- ìë§‰/í™”ë©´ ì„¤ì • ----
with st.expander("â± ìë§‰ íƒ€ì´ë° / ì†ë„ ì„¤ì •", expanded=True):
    max_chars_per_sub = st.slider(
        "ìë§‰ í•œ ì¤„ì— ë“¤ì–´ê°ˆ ìµœëŒ€ ê¸€ì ìˆ˜ (ìë™ ì˜ë¼ë‚¼ ê¸°ì¤€)",
        min_value=12,
        max_value=40,
        value=28,
        step=2,
    )
    chars_per_second = st.slider(
        "ì´ˆë‹¹ ê¸€ì ìˆ˜ (ê°’ì´ í´ìˆ˜ë¡ ìë§‰ì´ ë¹¨ë¦¬ ë„˜ì–´ê°)",
        min_value=3.0,
        max_value=20.0,
        value=8.0,
        step=0.5,
    )
    min_duration = st.slider(
        "í•œ ë¬¸ì¥ ìµœì†Œ í‘œì‹œ ì‹œê°„ (ì´ˆ)",
        min_value=0.5,
        max_value=5.0,
        value=1.5,
        step=0.1,
    )
    gap_between_lines = st.slider(
        "ìë§‰ ì‚¬ì´ ê³µë°± ì‹œê°„ (ì´ˆ)",
        min_value=0.0,
        max_value=1.5,
        value=0.2,
        step=0.1,
    )

with st.expander("ğŸ¨ ìë§‰ ìŠ¤íƒ€ì¼ / í™”ë©´ ì„¤ì •", expanded=False):
    subtitle_fontsize = st.slider(
        "ìë§‰ ê¸€ì í¬ê¸°",
        min_value=30,
        max_value=90,
        value=60,
        step=2,
    )
    subtitle_bottom_margin = st.slider(
        "í™”ë©´ ì•„ë˜ì—ì„œ ìë§‰ê¹Œì§€ ê°„ê²© (px)",
        min_value=100,
        max_value=500,
        value=280,
        step=10,
    )
    max_text_width_ratio = st.slider(
        "ìë§‰ ê°€ë¡œ í­ ë¹„ìœ¨ (í™”ë©´ ëŒ€ë¹„)",
        min_value=0.5,
        max_value=0.95,
        value=0.8,
        step=0.05,
    )

    text_color_name = st.selectbox(
        "ìë§‰ ìƒ‰ìƒ",
        ["white", "yellow"],
        index=0,
    )

    bg_color_name = st.selectbox(
        "ë°°ê²½ ìƒ‰ìƒ",
        ["black", "dark_gray", "navy_like"],
        index=0,
    )

    if bg_color_name == "black":
        bg_color = (0, 0, 0)
    elif bg_color_name == "dark_gray":
        bg_color = (20, 20, 20)
    else:
        bg_color = (10, 10, 40)

# ---- ìŒì„± ì„¤ì • ----
with st.expander("ğŸ™ ìŒì„±(TTS) ì„¤ì •", expanded=True):
    voice_choice = st.selectbox(
        "ëª©ì†Œë¦¬ ì„ íƒ (OpenAI TTS)",
        [
            "alloy",
            "ash",
            "ballad",
            "coral",
            "echo",
            "fable",
            "onyx",
            "nova",
            "sage",
            "shimmer",
            "verse",
        ],
        index=0,
    )
    voice_speed = st.slider(
        "ìŒì„± ì†ë„ (1.0 = ë³´í†µ)",
        min_value=0.5,
        max_value=1.5,
        value=1.0,
        step=0.05,
    )
    st.caption("â€» ë„ˆë¬´ ë¹ ë¥´ê²Œ í•˜ë©´ ë°œìŒì´ ë¶€ìì—°ìŠ¤ëŸ¬ì›Œì§ˆ ìˆ˜ ìˆì–´ìš”.")

VIDEO_WIDTH = 1080
VIDEO_HEIGHT = 1920

col1, col2 = st.columns(2)
preview_button = col1.button("ğŸ” ìë§‰ ë¯¸ë¦¬ë³´ê¸°", use_container_width=True)
generate_button = col2.button("ğŸ“½ ì˜ìƒ ìƒì„±", use_container_width=True)

# =========================
# 6. ìë§‰ ë¯¸ë¦¬ë³´ê¸°
# =========================
if preview_button:
    if not script_text.strip():
        st.warning("ë¨¼ì € ëŒ€ë³¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        subtitles = build_subtitles(
            script_text,
            chars_per_second=chars_per_second,
            min_duration=min_duration,
            gap_between_lines=gap_between_lines,
            max_chars_per_sub=max_chars_per_sub,
        )

        st.markdown("### ğŸ” ìë§‰ íƒ€ì„ë¼ì¸ (ìƒìœ„ 12ê°œ)")
        preview_rows = []
        for sub in subtitles[:12]:
            preview_rows.append(
                f"{sub['index']:>2} | {sub['start']:6.2f} â†’ {sub['end']:6.2f} | {sub['text']}"
            )
        st.code("\n".join(preview_rows) or "ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤.", language="text")

        preview_img = generate_preview_image(
            subtitles,
            VIDEO_WIDTH,
            VIDEO_HEIGHT,
            subtitle_fontsize,
            subtitle_bottom_margin,
            text_color_name,
            bg_color,
            max_text_width_ratio,
        )
        st.image(preview_img, caption="ìë§‰ í™”ë©´ ë¯¸ë¦¬ë³´ê¸° (1ë²ˆì§¸ ë¬¸ì¥ ê¸°ì¤€)", use_column_width=True)

# =========================
# 7. ì˜ìƒ ìƒì„±
# =========================
if generate_button:
    if not script_text.strip():
        st.warning("ë¨¼ì € ëŒ€ë³¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    with st.spinner("1/3 ìë§‰ íƒ€ì„ë¼ì¸ ë§Œë“œëŠ” ì¤‘..."):
        subtitles = build_subtitles(
            script_text,
            chars_per_second=chars_per_second,
            min_duration=min_duration,
            gap_between_lines=gap_between_lines,
            max_chars_per_sub=max_chars_per_sub,
        )

    with st.spinner("2/3 ìŒì„± ìƒì„± ì¤‘ (ChatGPT TTS)â€¦"):
        audio_path = generate_tts_audio(
            script_text,
            voice=voice_choice,
            speed=voice_speed,
        )

    st.markdown("### ğŸ” ìë§‰ íƒ€ì„ë¼ì¸ (ìƒìœ„ 12ê°œ)")
    preview_rows = []
    for sub in subtitles[:12]:
        preview_rows.append(
            f"{sub['index']:>2} | {sub['start']:6.2f} â†’ {sub['end']:6.2f} | {sub['text']}"
        )
    st.code("\n".join(preview_rows) or "ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤.", language="text")

    preview_img = generate_preview_image(
        subtitles,
        VIDEO_WIDTH,
        VIDEO_HEIGHT,
        subtitle_fontsize,
        subtitle_bottom_margin,
        text_color_name,
        bg_color,
        max_text_width_ratio,
    )
    st.image(preview_img, caption="ìë§‰ í™”ë©´ ë¯¸ë¦¬ë³´ê¸° (1ë²ˆì§¸ ë¬¸ì¥ ê¸°ì¤€)", use_column_width=True)

    with st.spinner("3/3 ì˜ìƒ ë Œë”ë§ ì¤‘... (ì¡°ê¸ˆ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)"):
        video_path = subtitles_to_video(
            audio_path,
            subtitles,
            VIDEO_WIDTH,
            VIDEO_HEIGHT,
            subtitle_fontsize,
            subtitle_bottom_margin,
            text_color_name,
            bg_color,
            max_text_width_ratio,
            fps=30,
        )

    st.success("ì˜ìƒ ìƒì„± ì™„ë£Œ!")

    with open(video_path, "rb") as vf:
        video_bytes = vf.read()

    st.video(video_bytes)
    st.download_button(
        "ğŸ’¾ ì˜ìƒ ë‹¤ìš´ë¡œë“œ (mp4)",
        data=video_bytes,
        file_name="subking_output.mp4",
        mime="video/mp4",
    )
