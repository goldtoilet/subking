import streamlit as st
from openai import OpenAI
import os
from moviepy.editor import AudioFileClip, TextClip, CompositeVideoClip, ColorClip
import numpy as np

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# -----------------------------
# 1) Text â†’ Speech (TTS)
# -----------------------------
def generate_tts(text, output_path="output.mp3"):
    response = client.audio.speech.create(
        model="gpt-4o-mini-tts",
        voice="alloy",
        input=text
    )

    # ì‘ë‹µì€ bytes
    audio_bytes = response.read()
    with open(output_path, "wb") as f:
        f.write(audio_bytes)

    return output_path


# -----------------------------
# 2) Whisper â†’ Timestamps
# -----------------------------
def extract_timestamps(audio_path):
    with open(audio_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            timestamp_granularities=["word"]  # ë˜ëŠ” ["segment"]
        )
    return transcript


# -----------------------------
# 3) íƒ€ì„ìŠ¤íƒ¬í”„ì—ì„œ ìë§‰ êµ¬ê°„ ë§Œë“¤ê¸°
# -----------------------------
def build_subtitle_segments(transcript):
    segments = []

    for w in transcript.words:
        segments.append({
            "text": w.word,
            "start": w.start,
            "end": w.end,
        })
    return segments


# -----------------------------
# 4) ì˜ìƒ ìƒì„±
# -----------------------------
def create_video(audio_path, segments, output="result.mp4"):

    # Video size
    W, H = 1080, 1920

    clips = []

    # ë°°ê²½ (ê²€ì •)
    bg = ColorClip(size=(W, H), color=(0, 0, 0), duration=segments[-1]["end"])
    clips.append(bg)

    # ìë§‰ ìƒì„±
    for seg in segments:
        txt = seg["text"]
        start = seg["start"]
        end = seg["end"]

        text_clip = TextClip(
            txt,
            font="Arial-Bold",
            fontsize=70,
            color="white",
            stroke_color="black",
            stroke_width=3,
            method="caption",
            align="center",
            size=(W - 200, None),
        ).set_position(("center", H - 300)).set_start(start).set_duration(end - start)

        clips.append(text_clip)

    final = CompositeVideoClip(clips)

    audio = AudioFileClip(audio_path)
    final = final.set_audio(audio)

    final.write_videofile(output, fps=30, codec="libx264", audio_codec="aac")

    return output


# -----------------------------
# Streamlit UI
# -----------------------------
st.title("ğŸ¬ SubKing - ì˜¤ë””ì˜¤ + íƒ€ì„ìŠ¤íƒ¬í”„ ìë§‰ ìë™ ìƒì„±ê¸°")

script = st.text_area("ëŒ€ë³¸ì„ ì…ë ¥í•˜ì„¸ìš”", height=250)

if st.button("ğŸ¤ ìŒì„± + ìë§‰ ì˜ìƒ ìƒì„±"):
    if not script.strip():
        st.error("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”!")
        st.stop()

    st.info("TTS ìƒì„± ì¤‘â€¦")
    audio_path = generate_tts(script)

    st.info("íƒ€ì„ìŠ¤íƒ¬í”„ ë¶„ì„ ì¤‘â€¦")
    transcript = extract_timestamps(audio_path)

    st.info("ìë§‰ êµ¬ê°„ ìƒì„± ì¤‘â€¦")
    segments = build_subtitle_segments(transcript)

    st.info("ì˜ìƒ ìƒì„± ì¤‘â€¦ ìµœëŒ€ 1~2ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŒ.")
    video_path = create_video(audio_path, segments)

    st.success("ì™„ë£Œ!")
    st.video(video_path)
