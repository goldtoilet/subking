import os
import streamlit as st
from openai import OpenAI
from moviepy.editor import AudioFileClip, TextClip, CompositeVideoClip, ColorClip

# =========================
# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# =========================
api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")

if not api_key:
    st.error(
        "OPENAI_API_KEY ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
        "- Streamlit Cloudì˜ 'Edit secrets'ì—ì„œ\n"
        '  OPENAI_API_KEY = "sk-..." í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•´ ì£¼ì„¸ìš”.'
    )
    st.stop()

client = OpenAI(api_key=api_key)

# í°íŠ¸ (ë ˆí¬ ë£¨íŠ¸ì— NanumGothic.ttf ê°€ ìˆë‹¤ê³  ê°€ì •)
FONT_PATH = os.path.join(os.path.dirname(__file__), "NanumGothic.ttf")


# ====================================
# 1) í…ìŠ¤íŠ¸ -> ìŒì„± (OpenAI TTS)
# ====================================
def generate_tts(text: str, output_path: str = "tts_audio.mp3") -> str:
    """
    í…ìŠ¤íŠ¸ë¥¼ OpenAI TTSë¡œ mp3 íŒŒì¼ë¡œ ì €ì¥.
    format íŒŒë¼ë¯¸í„°ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šê³ , ì‘ë‹µ bytes ê·¸ëŒ€ë¡œ ì €ì¥.
    """
    response = client.audio.speech.create(
        model="gpt-4o-mini-tts",
        voice="alloy",
        input=text,
    )

    # ì‘ë‹µ ê°ì²´ì—ì„œ raw bytes ì½ê¸°
    audio_bytes = response.read()

    with open(output_path, "wb") as f:
        f.write(audio_bytes)

    return output_path


# ====================================
# 2) ìŒì„± -> íƒ€ì„ìŠ¤íƒ¬í”„ (Whisper)
# ====================================
def extract_word_timestamps(audio_path: str):
    """
    Whisper(whisper-1)ë¡œ ë‹¨ì–´ ë‹¨ìœ„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ.
    """
    with open(audio_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="verbose_json",
            timestamp_granularities=["word"],
        )

    # SDK ë²„ì „ì— ë”°ë¼ pydantic ê°ì²´ / dict ë‘˜ ë‹¤ ëŒ€ì‘
    words = getattr(transcript, "words", None)
    if words is None and isinstance(transcript, dict):
        words = transcript.get("words", [])

    if words is None:
        words = []

    return words


# ====================================
# 3) íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ìë§‰ + ë°°ê²½ í´ë¦½ ìƒì„±
# ====================================
def build_video_clips_from_words(words, video_size=(1080, 1920)):
    """
    Whisper ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ìë§‰ í…ìŠ¤íŠ¸ í´ë¦½ + ë°°ê²½ í´ë¦½ ìƒì„±.
    """
    W, H = video_size
    clips = []

    if not words:
        return clips, 0.0

    # ì „ì²´ ê¸¸ì´
    last_end = max((w.end if hasattr(w, "end") else w["end"]) for w in words)

    # ë°°ê²½(ê²€ì • í™”ë©´)
    bg = ColorClip(size=(W, H), color=(0, 0, 0), duration=last_end)
    clips.append(bg)

    # ê° ë‹¨ì–´ë³„ ìë§‰ í´ë¦½
    for w in words:
        if hasattr(w, "word"):
            txt = w.word
            start = w.start
            end = w.end
        else:
            txt = w["word"]
            start = w["start"]
            end = w["end"]

        if end <= start:
            continue

        # í°íŠ¸ ê²½ë¡œê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸
        font_arg = FONT_PATH if os.path.isfile(FONT_PATH) else "Arial-Bold"

        text_clip = (
            TextClip(
                txt,
                font=font_arg,
                fontsize=70,
                color="white",
                stroke_color="black",
                stroke_width=3,
                method="caption",
                size=(W - 200, None),
            )
            .set_position(("center", H - 300))
            .set_start(start)
            .set_duration(end - start)
        )

        clips.append(text_clip)

    return clips, last_end


# ====================================
# 4) ìŒì„± + ìë§‰ -> mp4 ì˜ìƒ ë§Œë“¤ê¸°
# ====================================
def create_video_with_subtitles(
    audio_path: str, words, output_path: str = "subking_result.mp4"
):
    clips, duration = build_video_clips_from_words(words)
    if duration <= 0:
        return None

    video = CompositeVideoClip(clips)
    audio = AudioFileClip(audio_path)
    video = video.set_audio(audio)

    # mp4ë¡œ ë Œë”ë§
    video.write_videofile(
        output_path,
        fps=30,
        codec="libx264",
        audio_codec="aac",
        verbose=False,
        logger=None,
    )

    return output_path


# ====================================
# 5) Streamlit UI
# ====================================
st.set_page_config(page_title="SubKing", page_icon="ğŸ¬", layout="centered")

st.title("ğŸ¬ SubKing - í…ìŠ¤íŠ¸ë¡œ ìŒì„± + ìë§‰ ì˜ìƒ ë§Œë“¤ê¸°")

script = st.text_area(
    "ëŒ€ë³¸ì„ ì…ë ¥í•˜ì„¸ìš”",
    height=250,
    placeholder="ì—¬ê¸°ì— ì½ì–´ ì¤„ ë¬¸ì¥ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
)

if st.button("ğŸ¤ ìŒì„± + ìë§‰ ì˜ìƒ ìƒì„±"):
    if not script.strip():
        st.error("ëŒ€ë³¸ì„ ë¨¼ì € ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        st.stop()

    with st.status("TTS ìƒì„± ì¤‘...", expanded=True) as status:
        # 1) ìŒì„± ìƒì„±
        audio_path = generate_tts(script)
        status.update(label="íƒ€ì„ìŠ¤íƒ¬í”„ ë¶„ì„ ì¤‘ (Whisper)...", state="running")

        # 2) íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
        words = extract_word_timestamps(audio_path)
        if not words:
            status.update(
                label="íƒ€ì„ìŠ¤íƒ¬í”„ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.",
                state="error",
            )
            st.stop()

        status.update(label="ì˜ìƒ ë Œë”ë§ ì¤‘ (MoviePy)...", state="running")

        # 3) ì˜ìƒ ìƒì„±
        video_path = create_video_with_subtitles(audio_path, words)

        if not video_path:
            status.update(label="ì˜ìƒ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", state="error")
            st.stop()

        status.update(label="ì™„ë£Œ! ğŸ‰", state="complete")

    st.success("ì˜ìƒì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.video(video_path)

    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    with open(video_path, "rb") as f:
        st.download_button(
            "ğŸ“¥ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
            f,
            file_name="subking_result.mp4",
            mime="video/mp4",
        )
